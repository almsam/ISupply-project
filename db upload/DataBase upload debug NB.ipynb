{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading our stuff, but without 10% loss\n",
    "\n",
    "    First, lets import our tools & ingredients again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ser                  combined\n",
      "0    1               Agriculture\n",
      "1    2    Agricultural Equipment\n",
      "2    3  Agricultural Greenhouses\n",
      "3    4     Aquaculture Equipment\n",
      "4    5          Aquaculture Trap\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('map.xlsx')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psycopg2.connect(database=\"iSupply\",\n",
    "                        host=\"38.180.117.52\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"deerRun\",\n",
    "                        port=\"5432\")\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_subcategory(df, index):\n",
    "    num = df.loc[index, 'Ser']\n",
    "    name = df.loc[index, 'combined']\n",
    "    return name, num\n",
    "\n",
    "def process_categories(df, cursor, con, start, end):\n",
    "    listOfCollisions = []; j = 0\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        name, num = get_category_subcategory(df, i); num = str(num)\n",
    "\n",
    "        try:\n",
    "            cursor.execute(\"\"\"INSERT INTO \"Categories\" (category_id, category) VALUES (%s, %s)\"\"\", (num, name))\n",
    "        except psycopg2.errors.UniqueViolation as e:\n",
    "            listOfCollisions.append(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "        \n",
    "        if(j==10):\n",
    "            con.commit(); j = 0 # this time we will commit for each 10th entry\n",
    "        j = j + 1\n",
    "\n",
    "    con.commit()\n",
    "\n",
    "    print(len(listOfCollisions)); return listOfCollisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wipe the db from DBeaver\n",
    "\n",
    "con = psycopg2.connect(database=\"iSupply\",\n",
    "                        host=\"38.180.117.52\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"deerRun\",\n",
    "                        port=\"5432\")\n",
    "cursor = con.cursor()\n",
    "\n",
    "for i in range(46): # first 46 hundreds - should do it, but 15 mins seems like an issue - but lets buckle up none the less\n",
    "    collisions = process_categories(df, cursor, con, (100*i), ((100*i)+100))\n",
    "    print(\"100 number \", (i+1) ,\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Now, lets run the first couple hundreds from the O(n) method, but lets make 1 key change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_subcategory(df, index):\n",
    "    num = df.loc[index, 'Ser']                                                                             # O( log(n) )\n",
    "    name = df.loc[index, 'combined']\n",
    "    return name, num\n",
    "\n",
    "def process_categories(df, cursor, con, start, end):\n",
    "    listOfCollisions = []; listOfAllErrors = []; j = 0\n",
    "    \n",
    "    for i in range(start, end):                                                                                 # O(n)\n",
    "        name, num = get_category_subcategory(df, i); num = str(num)\n",
    "\n",
    "        try:\n",
    "            cursor.execute(\"\"\"INSERT INTO \"Categories\" (category_id, category) VALUES (%s, %s)\"\"\", (num, name)) # O(n)\n",
    "        except psycopg2.errors.UniqueViolation as e:\n",
    "            listOfAllErrors.append(i); listOfCollisions.append(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            listOfAllErrors.append(i)\n",
    "        \n",
    "        if(j==10):\n",
    "            con.commit(); j = 0 # this time we will commit for each 10th entry\n",
    "        j = j + 1\n",
    "\n",
    "    con.commit()\n",
    "\n",
    "    print(len(listOfCollisions), len(listOfAllErrors)); return listOfCollisions, listOfAllErrors\n",
    "\n",
    "    # this should give us some details on where our data is going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfCollisions = []; listOfAllErrors = []\n",
    "\n",
    "# wipe the db from DBeaver\n",
    "con = psycopg2.connect(database=\"iSupply\", host=\"38.180.117.52\", user=\"postgres\", password=\"deerRun\", port=\"5432\"); cursor = con.cursor() # open\n",
    "\n",
    "for i in range(5): # first 5 hundreds for sake of inspection\n",
    "    collisions, errors = process_categories(df, cursor, con, (100*i), ((100*i)+100))\n",
    "    listOfCollisions.append(collisions); listOfAllErrors.append(errors)\n",
    "    print(\"100 number \", (i+1) ,\" done\")\n",
    "\n",
    "cursor.close(); con.close() # close\n",
    "\n",
    "# map, batch, batching\n",
    "# more then 1 value at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Upon realizing there is a better way to do this, its time to inspect the database for this instead\n",
    "\n",
    "    Lets inspect the dataset in DBeaver\n",
    "\n",
    "![DBeaver pic](DBeaverShot.PNG \"Screenshot from DBeaver\")\n",
    "\n",
    "    Looks like SER 142 through to 151 don't exist, I SHALL INSPECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ser                              combined\n",
      "135  136                              Palm Oil\n",
      "136  137                          Rapeseed Oil\n",
      "137  138                            Sesame Oil\n",
      "138  139                           Soybean Oil\n",
      "139  140                         Sunflower Oil\n",
      "140  141                         Plant Extract\n",
      "141  142                           Plant Fiber\n",
      "142  143                   Plant Seeds & Bulbs\n",
      "143  144       Flower Bulbs, Seeds & Seedlings\n",
      "144  145                          Forage Seeds\n",
      "145  146  Fruit Grafts, Seedlings & Rootstocks\n",
      "146  147                             Oil Seeds\n",
      "147  148                       Vegetable Seeds\n",
      "148  149                               Tobacco\n",
      "149  150                                   NaN\n",
      "150  151                                   NaN\n",
      "151  152                               Apparel\n",
      "152  153               Apparel Design Services\n",
      "153  154           Apparel Processing Services\n",
      "154  155                         Apparel Stock\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[135:155]) # I thought the issue was in the dataset, this piece of code was to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ser            combined\n",
      "125  126  Plant & Animal Oil\n",
      "126  127          Animal Oil\n",
      "127  128         Blended Oil\n",
      "128  129        Camellia Oil\n",
      "129  130          Castor Oil\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[125:130])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    so it isn't the ampersand thats messing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ser                    combined\n",
      "10   11  Agricultural Growing Media\n",
      "11   12                        Peat\n",
      "12   13  Agricultural Product Stock\n",
      "13   14          Agricultural Waste\n",
      "14   15              Animal Extract\n",
      "15   16                 Animal Feed\n",
      "16   17             Animal Products\n",
      "17   18                        Eggs\n",
      "18   19            Fowl & Livestock\n",
      "19   20        Bamboo Raw Materials\n",
      "20   21             Bean-Like Seeds\n",
      "21   22                       Cacao\n",
      "22   23                Coffee Beans\n",
      "23   24               Vanilla Beans\n",
      "24   25                       Beans\n",
      "25   26                 Broad Beans\n",
      "26   27                Butter Beans\n",
      "27   28                   Chickpeas\n",
      "28   29                Kidney Beans\n",
      "29   30                     Lentils\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[10:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Doesn't look like any pattern i've seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ser      combined\n",
      "25   26   Broad Beans\n",
      "26   27  Butter Beans\n",
      "27   28     Chickpeas\n",
      "28   29  Kidney Beans\n",
      "29   30       Lentils\n",
      "30   31    Lima Beans\n",
      "31   32   Other Beans\n",
      "32   33          Peas\n",
      "33   34      Soybeans\n",
      "34   35   Vigna Beans\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[25:35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    It definitely isn't the length of our strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ser               combined\n",
      "255  256       Pants & Trousers\n",
      "256  257        Sewing Supplies\n",
      "257  258  Other Sewing Supplies\n",
      "258  259         Sewing Needles\n",
      "259  260         Sewing Threads\n",
      "260  261     Tailor\\'s Scissors\n",
      "261  262                 Shorts\n",
      "262  263                 Skirts\n",
      "263  264              Sleepwear\n",
      "264  265               Babydoll\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[255:265])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    It also doesn't seem the backslash or apostrophe prevented it\n",
    "\n",
    "~~It seems like I will resign to the 90.33% of the data for now, however if this disrupts the tree construction significantly I will return to the experiment from earlier with a new debug lens~~\n",
    "\n",
    "    Time to run the experiment from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "100 number  1  done\n",
      "1 1\n",
      "100 number  2  done\n",
      "0 0\n",
      "100 number  3  done\n",
      "Error occurred: current transaction is aborted, commands ignored until end of transaction block\n",
      "\n",
      "1 2\n",
      "100 number  4  done\n",
      "0 0\n",
      "100 number  5  done\n"
     ]
    }
   ],
   "source": [
    "listOfCollisions = []; listOfAllErrors = []\n",
    "\n",
    "# wipe the db from DBeaver\n",
    "con = psycopg2.connect(database=\"iSupply\", host=\"38.180.117.52\", user=\"postgres\", password=\"deerRun\", port=\"5432\"); cursor = con.cursor() # open\n",
    "\n",
    "for i in range(5): # first 5 hundreds for sake of inspection\n",
    "    collisions, errors = process_categories(df, cursor, con, (100*i), ((100*i)+100))\n",
    "    listOfCollisions += collisions; listOfAllErrors += errors\n",
    "    print(\"100 number \", (i+1) ,\" done\")\n",
    "\n",
    "cursor.close(); con.close() # close\n",
    "\n",
    "# map, batch, batching\n",
    "# more then 1 value at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors  [150, 339, 340]\n",
      "; collisions  [150, 339]\n"
     ]
    }
   ],
   "source": [
    "print(\"errors \", listOfAllErrors);      print(\"; collisions \", listOfCollisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ser combined\n",
      "150  151      NaN\n",
      "     Ser                    combined\n",
      "339  340                         NaN\n",
      "340  341  Automobiles & Motorcycle s\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[150:151]); print(df.iloc[339:341])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Interesting, lets check DBeaver\n",
    "\n",
    "![DBeaver pic 2](DBeaverShotEndIndex.PNG \"Screenshot from DBeaver\")\n",
    "\n",
    "    looks like SER 500 was 480th\n",
    "\n",
    "    Lets run that again for more inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listOfCollisions = []; listOfAllErrors = []\n",
    "\n",
    "# # wipe the db from DBeaver\n",
    "# con = psycopg2.connect(database=\"iSupply\", host=\"38.180.117.52\", user=\"postgres\", password=\"deerRun\", port=\"5432\"); cursor = con.cursor() # open\n",
    "\n",
    "# for i in range(5): # first 5 hundreds for sake of inspection\n",
    "#     collisions, errors = process_categories(df, cursor, con, (100*i), ((100*i)+100))\n",
    "#     listOfCollisions += collisions; listOfAllErrors += errors\n",
    "#     print(\"100 number \", (i+1) ,\" done\")\n",
    "\n",
    "# cursor.close(); con.close() # close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
